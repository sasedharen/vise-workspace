# AlertManager Rules for GitLab CI/CD Pipeline Monitoring
# Designed for 500 developers with performance and reliability focus

groups:
  # Critical system alerts
  - name: system.critical
    rules:
      - alert: HighCPUUsage
        expr: system:cpu_utilization_5m > 85
        for: 5m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is {{ $value }}% on {{ $labels.instance }}"

      - alert: HighMemoryUsage
        expr: system:memory_utilization_5m > 90
        for: 5m
        labels:
          severity: critical
          service: system
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is {{ $value }}% on {{ $labels.instance }}"

      - alert: DiskSpaceLow
        expr: system:disk_utilization_5m > 85
        for: 10m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "Disk space running low"
          description: "Disk usage is {{ $value }}% on {{ $labels.instance }}"

      - alert: DiskSpaceCritical
        expr: system:disk_utilization_5m > 95
        for: 2m
        labels:
          severity: critical
          service: system
        annotations:
          summary: "Disk space critically low"
          description: "Disk usage is {{ $value }}% on {{ $labels.instance }}"

  # GitLab service alerts
  - name: gitlab.alerts
    rules:
      - alert: GitLabDown
        expr: up{job="gitlab"} == 0
        for: 1m
        labels:
          severity: critical
          service: gitlab
        annotations:
          summary: "GitLab is down"
          description: "GitLab instance {{ $labels.instance }} is down"

      - alert: GitLabHighResponseTime
        expr: gitlab_http_request_duration_seconds{quantile="0.95"} > 5
        for: 5m
        labels:
          severity: warning
          service: gitlab
        annotations:
          summary: "GitLab high response time"
          description: "95th percentile response time is {{ $value }}s"

      - alert: GitLabPipelineFailureRate
        expr: gitlab:pipeline_success_rate_5m < 0.8
        for: 10m
        labels:
          severity: warning
          service: gitlab-ci
        annotations:
          summary: "High pipeline failure rate"
          description: "Pipeline success rate is {{ $value | humanizePercentage }} over the last 5 minutes"

      - alert: GitLabPipelineQueueTime
        expr: gitlab:build_queue_time_p95_5m > 300
        for: 5m
        labels:
          severity: warning
          service: gitlab-ci
        annotations:
          summary: "High pipeline queue time"
          description: "95th percentile queue time is {{ $value }}s"

  # GitLab Runner alerts
  - name: gitlab-runner.alerts
    rules:
      - alert: GitLabRunnerDown
        expr: up{job=~"gitlab-runner-.*"} == 0
        for: 2m
        labels:
          severity: critical
          service: gitlab-runner
        annotations:
          summary: "GitLab Runner is down"
          description: "GitLab Runner {{ $labels.instance }} is down"

      - alert: GitLabRunnerHighConcurrency
        expr: gitlab_runner:concurrent_limit_utilization > 90
        for: 5m
        labels:
          severity: warning
          service: gitlab-runner
        annotations:
          summary: "GitLab Runner high concurrency"
          description: "Runner {{ $labels.instance }} is at {{ $value }}% of concurrent limit"

      - alert: GitLabRunnerJobFailures
        expr: rate(gitlab_runner_failed_jobs_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
          service: gitlab-runner
        annotations:
          summary: "High job failure rate on runner"
          description: "Runner {{ $labels.instance }} has {{ $value }} job failures per second"

      - alert: GitLabRunnerStuckJobs
        expr: gitlab_runner_jobs{state="running"} > 10
        for: 30m
        labels:
          severity: warning
          service: gitlab-runner
        annotations:
          summary: "Runner has stuck jobs"
          description: "Runner {{ $labels.instance }} has {{ $value }} jobs running for more than 30 minutes"

  # Database alerts
  - name: database.alerts
    rules:
      - alert: PostgreSQLDown
        expr: up{job="postgresql"} == 0
        for: 1m
        labels:
          severity: critical
          service: postgresql
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL instance {{ $labels.instance }} is down"

      - alert: PostgreSQLHighConnections
        expr: pg_stat_activity_count > 80
        for: 5m
        labels:
          severity: warning
          service: postgresql
        annotations:
          summary: "PostgreSQL high connection count"
          description: "PostgreSQL has {{ $value }} active connections"

      - alert: PostgreSQLSlowQueries
        expr: pg_stat_activity_max_tx_duration > 300
        for: 5m
        labels:
          severity: warning
          service: postgresql
        annotations:
          summary: "PostgreSQL slow queries detected"
          description: "Longest running query is {{ $value }}s"

      - alert: PostgreSQLReplicationLag
        expr: pg_stat_replication_lag > 30
        for: 2m
        labels:
          severity: warning
          service: postgresql
        annotations:
          summary: "PostgreSQL replication lag"
          description: "Replication lag is {{ $value }}s"

  # Redis alerts
  - name: redis.alerts
    rules:
      - alert: RedisDown
        expr: up{job="redis"} == 0
        for: 1m
        labels:
          severity: critical
          service: redis
        annotations:
          summary: "Redis is down"
          description: "Redis instance {{ $labels.instance }} is down"

      - alert: RedisHighMemoryUsage
        expr: redis_memory_used_rss_bytes / redis_memory_max_bytes > 0.9
        for: 5m
        labels:
          severity: warning
          service: redis
        annotations:
          summary: "Redis high memory usage"
          description: "Redis memory usage is {{ $value | humanizePercentage }}"

      - alert: RedisHighConnections
        expr: redis_connected_clients > 100
        for: 5m
        labels:
          severity: warning
          service: redis
        annotations:
          summary: "Redis high connection count"
          description: "Redis has {{ $value }} connected clients"

  # Container alerts
  - name: container.alerts
    rules:
      - alert: ContainerCPUUsage
        expr: container:cpu_usage_rate_5m > 0.8
        for: 10m
        labels:
          severity: warning
          service: docker
        annotations:
          summary: "Container high CPU usage"
          description: "Container {{ $labels.name }} CPU usage is {{ $value | humanizePercentage }}"

      - alert: ContainerMemoryUsage
        expr: container:memory_usage_bytes / container_spec_memory_limit_bytes > 0.9
        for: 5m
        labels:
          severity: warning
          service: docker
        annotations:
          summary: "Container high memory usage"
          description: "Container {{ $labels.name }} memory usage is {{ $value | humanizePercentage }}"

      - alert: ContainerRestartLoop
        expr: increase(container_last_seen[1h]) > 5
        for: 5m
        labels:
          severity: warning
          service: docker
        annotations:
          summary: "Container restart loop detected"
          description: "Container {{ $labels.name }} has restarted {{ $value }} times in the last hour"

  # Security alerts
  - name: security.alerts
    rules:
      - alert: SecurityScanFailure
        expr: increase(gitlab_ci_pipeline_builds_total{stage="security",status="failed"}[1h]) > 3
        for: 5m
        labels:
          severity: warning
          service: security
        annotations:
          summary: "Multiple security scan failures"
          description: "{{ $value }} security scans have failed in the last hour"

      - alert: HighVulnerabilityCount
        expr: security_vulnerabilities_total{severity="critical"} > 0
        for: 1m
        labels:
          severity: critical
          service: security
        annotations:
          summary: "Critical vulnerabilities detected"
          description: "{{ $value }} critical vulnerabilities found in security scan"

      - alert: ContainerImageVulnerabilities
        expr: trivy_vulnerabilities_total{severity="high"} > 10
        for: 5m
        labels:
          severity: warning
          service: security
        annotations:
          summary: "High number of container vulnerabilities"
          description: "{{ $value }} high-severity vulnerabilities found in container images"

  # Performance alerts for 500 developers
  - name: performance.500dev
    rules:
      - alert: PipelineThroughputLow
        expr: rate(gitlab_ci_pipeline_builds_total[5m]) < 5
        for: 10m
        labels:
          severity: warning
          service: gitlab-ci
        annotations:
          summary: "Low pipeline throughput"
          description: "Pipeline execution rate is {{ $value }} per second, expected > 5 for 500 developers"

      - alert: RunnerScalingNeeded
        expr: sum(gitlab_runner_jobs{state="pending"}) > 20
        for: 5m
        labels:
          severity: warning
          service: gitlab-runner
        annotations:
          summary: "Runner scaling needed"
          description: "{{ $value }} jobs are pending execution, consider adding more runners"

      - alert: BuildTimeIncreasing
        expr: increase(gitlab_ci_build_duration_seconds_sum[1h]) / increase(gitlab_ci_build_duration_seconds_count[1h]) > 1800
        for: 10m
        labels:
          severity: warning
          service: gitlab-ci
        annotations:
          summary: "Average build time increasing"
          description: "Average build time is {{ $value }}s, investigate performance issues"

      - alert: ArtifactStorageGrowth
        expr: increase(gitlab_artifacts_size_bytes[1h]) > 10737418240  # 10GB
        for: 5m
        labels:
          severity: warning
          service: gitlab
        annotations:
          summary: "High artifact storage growth"
          description: "Artifact storage increased by {{ $value | humanizeBytes }} in the last hour"